{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Facial Emotion Recognition on FER2013\n",
    "This notebook implements a deep learning pipeline using ResNet50V2 with CBAM and Focal Loss for emotion classification on the FER2013 dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b8f52d1b5e39c73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports and configurations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef1a7199f5d05135"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "PROJECT_ROOT = os.path.dirname(BASE_DIR)\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"train\", \"*\", \"*\")\n",
    "PLOTS_DIR = os.path.join(PROJECT_ROOT, \"results\",\"utils\",\"plots\")\n",
    "MODELS_CHECKPOINTS = os.path.join(PROJECT_ROOT,\"models\", \"checkpoints\",\"best_model.keras\")\n",
    "MODELS_FINAL_MODEL = os.path.join(PROJECT_ROOT,\"Models\", \"final\", \"final_model.keras\")\n",
    "\n",
    "\n",
    "# Constants\n",
    "INPUT_SIZE = 144\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# Label encoder and learning rate log\n",
    "le = LabelEncoder()\n",
    "lr_log = []\n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attention Block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ced46db97f20fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CBAMLayer(layers.Layer):\n",
    "    def __init__(self, ratio=8):\n",
    "        super(CBAMLayer, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # This ensures the variables are created only once when the layer is first called.\n",
    "        self.channel = input_shape[-1]\n",
    "\n",
    "        # Channel Attention\n",
    "        self.shared_dense_one = layers.Dense(self.channel // self.ratio, activation='relu')\n",
    "        self.shared_dense_two = layers.Dense(self.channel)\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.spatial_conv = layers.Conv2D(1, (7, 7), padding='same', activation='sigmoid')\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        # Channel Attention\n",
    "        avg_pool = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "        max_pool = layers.GlobalMaxPooling2D()(input_tensor)\n",
    "\n",
    "        avg = self.shared_dense_one(avg_pool)\n",
    "        avg = self.shared_dense_two(avg)\n",
    "\n",
    "        max = self.shared_dense_one(max_pool)\n",
    "        max = self.shared_dense_two(max)\n",
    "\n",
    "        channel_attention = layers.Add()([avg, max])\n",
    "        channel_attention = layers.Activation('sigmoid')(channel_attention)\n",
    "        channel_attention = layers.Reshape((1, 1, self.channel))(channel_attention)\n",
    "        x = layers.Multiply()([input_tensor, channel_attention])\n",
    "\n",
    "        # Spatial Attention\n",
    "        avg_pool = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        spatial_attention = self.spatial_conv(concat)\n",
    "        x = layers.Multiply()([x, spatial_attention])\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e701213a50bf0ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Focal loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77bf88e07e8c7542"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        weight = alpha * K.pow(1 - y_pred, gamma)\n",
    "        return K.mean(weight * cross_entropy)\n",
    "\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d6a12ddae8cc64c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Learning Rate Scheduler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22d14003b7db3fc4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "learning_rate = CosineDecay(initial_learning_rate=0.001, decay_steps=1000, alpha=0.1)\n",
    "\n",
    "\n",
    "class LogCosineDecay(Callback):\n",
    "    def __init__(self, lr_schedule, log_storage):\n",
    "        super().__init__()\n",
    "        self.lr_schedule = lr_schedule\n",
    "        self.log_storage = log_storage\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        steps = len(self.model.history.epoch) * len(self.model.history.history.get('loss', []))\n",
    "        current_lr = float(self.lr_schedule(epoch * steps))\n",
    "        self.log_storage.append(current_lr)\n",
    "        print(f\"Epoch {epoch + 1}: Learning Rate = {current_lr:.6f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2e9aa174016482"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba47130797ecce84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data, labels = [], []\n",
    "\n",
    "    for i, path in enumerate(glob.glob(DATA_DIR)):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        img = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))\n",
    "        img = preprocess_input(img)\n",
    "        data.append(img)\n",
    "\n",
    "        label = path.split(\"\\\\\")[-2]\n",
    "        labels.append(label)\n",
    "\n",
    "        if i % 2870 == 0:\n",
    "            print(f\"{i}/28708 samples loaded\")\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = le.fit_transform(labels)\n",
    "    labels = to_categorical(labels, NUM_CLASSES)\n",
    "\n",
    "    return train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4e5e783dc510e16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e24f007f0c7d697"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augment_data(x_train):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "    return datagen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41379b695b8e4488"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Builder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a029b9c4dfbf7795"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "    for layer in base_model.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = CBAMLayer()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(2048, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=focal_loss(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d8ed18fb9238d2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c290ff668cb9f94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, datagen, x_train, y_train, x_val, y_val):\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(MODELS_CHECKPOINTS, save_best_only=True, monitor=\"val_loss\", mode=\"min\", verbose=1),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "        LogCosineDecay(learning_rate, lr_log)\n",
    "    ]\n",
    "    weights = class_weight.compute_class_weight(\"balanced\", np.unique(np.argmax(y_train, axis=1)),\n",
    "                                                np.argmax(y_train, axis=1))\n",
    "    weights = dict(enumerate(weights))\n",
    "\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=weights\n",
    "    )\n",
    "    model.save(MODELS_FINAL_MODEL)\n",
    "    loss, acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "    print(f\"\\nTest Loss: {loss:.4f} | Test Accuracy: {acc:.4f}\")\n",
    "    return history\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccf3897c1a42763"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d716a85c8304804"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_val, y_val):\n",
    "    y_pred = np.argmax(model.predict(x_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a55c62d9bb571a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbdce02c8fa4e4b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_history(H):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"Train Accuracy\", color=\"blue\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"Val Accuracy\", color=\"green\")\n",
    "    plt.title(\"Train vs Test Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, 'accuracy.png'))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(H.history[\"loss\"], label=\"Train Loss\", color=\"red\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"Val Loss\", color=\"orange\")\n",
    "    plt.title(\"Train vs Test Loss\")\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, 'loss.png'))\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a01ee7bda9fa4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d6d03d298b504e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = load_data()\n",
    "datagen = augment_data(x_train)\n",
    "model = build_model()\n",
    "history = train_model(model, datagen, x_train, y_train, x_val, y_val)\n",
    "evaluate_model(model, x_val, y_val)\n",
    "plot_history(history)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0338c1a1887e52b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
